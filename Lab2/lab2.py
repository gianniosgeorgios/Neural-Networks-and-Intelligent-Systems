# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CfqP4ux4QE72LMLmTpBHAD_eqDciVAtd

# Εργαστηριακή Άσκηση 2. Μη επιβλεπόμενη μάθηση. 
## Σύστημα συστάσεων βασισμένο στο περιεχόμενο
## Σημασιολογική απεικόνιση δεδομένων με χρήση SOM
"""

!pip install num2words
!pip install --upgrade pip
!pip install --upgrade nltk
!pip install --upgrade numpy
!pip install --upgrade pandas
!pip install --upgrade joblib
!pip install --upgrade somoclu
!pip install --upgrade scikit-learn

# Commented out IPython magic to ensure Python compatibility.
import nltk
import string
import joblib
import somoclu
import num2words
import matplotlib
import numpy as np
import scipy as sp
import collections
import pandas as pd
from nltk import word_tokenize  
from nltk.corpus import stopwords
from sklearn.cluster import KMeans
from nltk.stem import WordNetLemmatizer 
from sklearn.feature_extraction import text
from nltk.stem.snowball import SnowballStemmer
from sklearn.feature_extraction.text import TfidfVectorizer

# %matplotlib inline

nltk.download('names')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords') # κατεβάζουμε ένα αρχείο που έχει stopwords στα αγγλικά

"""## Εισαγωγή του Dataset

Το σύνολο δεδομένων με το οποίο δουλεύουμε είναι βασισμένο στο [Carnegie Mellon Movie Summary Corpus](http://www.cs.cmu.edu/~ark/personas/). Πρόκειται για ένα dataset με περίπου 40.000 περιγραφές ταινιών. Η περιγραφή κάθε ταινίας αποτελείται από τον τίτλο της, μια ή περισσότερες ετικέτες που χαρακτηρίζουν το είδος της ταινίας και τέλος τη σύνοψη της υπόθεσής της. Αρχικά εισάγουμε το dataset  στο dataframe `df_data_1`:
"""

dataset_url = "https://drive.google.com/uc?export=download&id=1PdkVDENX12tQliCk_HtUnAUbfxXvnWuG"
df_data_1 = pd.read_csv(dataset_url, sep='\t',  header=None, quoting=3, error_bad_lines=False)

"""Απο τις παραπάνω ταινίες επιλέγουμε αυτές που αντιστοιχούν στον αριθμό της ομάδας μας. """

#Βάζουμε το seed που αντιστοιχεί στην ομάδα σας
team_seed_number = 70

movie_seeds_url = "https://drive.google.com/uc?export=download&id=1EA_pUIgK5Ub3kEzFbFl8wSRqAV6feHqD"
df_data_2 = pd.read_csv(movie_seeds_url, header=None, error_bad_lines=False)

#Αποθήκευση Τίτλων,Κατηγοριών και περιλήψεων
my_index = df_data_2.iloc[team_seed_number,:].values

titles = df_data_1.iloc[:, [2]].values[my_index]      # Τίτλοι
categories = df_data_1.iloc[:, [3]].values[my_index]  # Κατηγορίες (string)
bins = df_data_1.iloc[:, [4]]
catbins = bins[4].str.split(',', expand=True).values.astype(np.float)[my_index] # Κατηγορίες (one hot κωδικοποίηση)
summaries =  df_data_1.iloc[:, [5]].values[my_index]                            # Υποθέσεις ταινιών (string)
corpus = summaries[:,0].tolist()                                                # Υποθέσεις ταινιών (list)

"""## Επισκόπηση Dataset

- Ο πίνακας **titles** περιέχει τους τίτλους των ταινιών. Παράδειγμα: 'Sid and Nancy'.
- O πίνακας **categories** περιέχει τις κατηγορίες (είδη) της ταινίας υπό τη μορφή string. Παράδειγμα: '"Tragedy",  "Indie",  "Punk rock",  "Addiction Drama",  "Cult",  "Musical",  "Drama",  "Biopic \[feature\]",  "Romantic drama",  "Romance Film",  "Biographical film"'. Παρατηρούμε ότι είναι μια comma separated λίστα strings, με κάθε string να είναι μια κατηγορία.
- Ο πίνακας **catbins** περιλαμβάνει πάλι τις κατηγορίες των ταινιών αλλά σε δυαδική μορφή ([one hot encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)). Έχει διαστάσεις 5.000 x 322 (όσες οι διαφορετικές κατηγορίες). Αν η ταινία ανήκει στο συγκεκριμένο είδος η αντίστοιχη στήλη παίρνει την τιμή 1, αλλιώς παίρνει την τιμή 0.
- Ο πίνακας **summaries** και η λίστα **corpus** περιλαμβάνουν τις συνόψεις των ταινιών (η corpus είναι απλά ο summaries σε μορφή λίστας). Κάθε σύνοψη είναι ένα (συνήθως μεγάλο) string. Παράδειγμα: *'The film is based on the real story of a Soviet Internal Troops soldier who killed his entire unit  as a result of Dedovschina. The plot unfolds mostly on board of the prisoner transport rail car guarded by a unit of paramilitary conscripts.'*
- Θεωρούμε ως **ID** της κάθε ταινίας τον αριθμό γραμμής της ή το αντίστοιχο στοιχείο της λίστας.

# Εφαρμογή 1. Υλοποίηση συστήματος συστάσεων ταινιών βασισμένο στο περιεχόμενο
<img src="http://clture.org/wp-content/uploads/2015/12/Netflix-Streaming-End-of-Year-Posts.jpg" width="70%">

## Περιγραφή της Εφαρμογής

Η πρώτη εφαρμογή που αναπτύσσουμε είναι ένα [σύστημα συστάσεων](https://en.wikipedia.org/wiki/Recommender_system) ταινιών βασισμένο στο περιεχόμενο (content based recommender system). Τα συστήματα συστάσεων στοχεύουν στο να προτείνουν αυτόματα στο χρήστη αντικείμενα από μια συλλογή τα οποία ιδανικά θέλουμε να βρει ενδιαφέροντα ο χρήστης. Η κατηγοριοποίηση των συστημάτων συστάσεων βασίζεται στο πώς γίνεται η επιλογή (filtering) των συστηνόμενων αντικειμένων. Οι δύο κύριες κατηγορίες είναι η συνεργατική διήθηση (collaborative filtering) όπου το σύστημα προτείνει στο χρήστη αντικείμενα που έχουν αξιολογηθεί θετικά από χρήστες που έχουν παρόμοιο με αυτόν ιστορικό αξιολογήσεων και η διήθηση με βάση το περιεχόμενο (content based filtering), όπου προτείνονται στο χρήστη αντικείμενα με παρόμοιο περιεχόμενο (με βάση κάποια χαρακτηριστικά) με αυτά που έχει προηγουμένως αξιολογήσει θετικά.

Το σύστημα συστάσεων που αναπτύσσουμε βασίζεται στο **περιεχόμενο** και συγκεκριμένα στις συνόψεις των ταινιών (corpus).

Η προσέγγιση που ακολουθούμε βασίζεται σε δύο συναρτήσεις. Η **πρώτη** συνάρτηση `TfidfVectorizer`, μετασχηματίζει το `corpus` σε TF-IDF αναπαράσταση. Πρόκειται για ένα πίνακα διαστάσεων (5000, πλήθος_όρων), κάθε τιμή του οποίου ειναι ενας αριθμός:

$$ tf(i,d)idf(i) = \frac{f(i,d)}{\sum_{i}f(i,d)}log \frac{N}{df(i)}$$

Όπου *i* ο όρος στο κείμενο *d*, *Ν* ο αριθμός των κειμένων και *df(i)* ο αριθμός των κειμένων στους οποίους εμφανίζεται ο όρος *i*. Το tf είναι στην ουσία η συχνότητα με την οποία εμφανίζεται ο κάθε όρος στο κείμενο ενώ το idf είναι ένας δείκτης της πληροφορίας που δίνει η κάθε λέξη

Η **δευτερη** (`content_recommender`), δέχεται σαν όρισμα το ID μιας ταινίας (`target_movie`) και έναν αριθμό (`max_recommendations`) που αντιστοιχεί στις πλήθος των προτεινώμενων απο το σύστημα ταινιών.Χρησιμοποιώντας τον `tf_idf` πίνακα υπολογίζει την ομοιότητα συνημιτόνου της `target_movie` με όλες τις υπόλοιπες.Έτσι επιστρέφει `max_recommendations`-προτάσεις (ΙD ταινιών).

Η πρώτη όμως συνάρτηση μπορεί να βελτιστοποιηθεί ώστε να μειωθεί η διάσταση του πίνακα `corpus_tf_idf`. H διαδικασία που ακολουθούμε είναι *bottom_up*. Aρχίζουμε με μια baseline προσέγγιση της `TfidfVectorizer`, και στην συνέχεια όσο τη παραμετροποιούμε παρατηρούμε τις προτάσεις ταινών (καλώντας την `content_recommender`)
"""

def content_recomneder(target_movie, max_recommendations):

  input_corpus = corpus_tf_idf 
  max_recommendations = max_recommendations + 1 
  ID = target_movie
  
  cos_sim = np.zeros(5000)

  # Στο αρχείο Recommendations.txt αποθηκεύουμε
  # αποθηκεύουμε τις πλοκές των προτεινόμενων ταινιών
  # καθώς είναι πιο εύκολη η ανάγνωση απο .txt
  open('Recommendations.txt', 'w').close()

  #Υπολογισμός της απόστασης συνημιτόνου
  for i in range(5000):
    cos_sim[i]= sp.spatial.distance.cosine(input_corpus[ID],input_corpus[i])
  
  #Επιλογή ID ταινιών με μικρότερη απόσταση συνημοτόνου
  #όσες ορίζονται απο τη παράμετρο max_recommendations
  indices = cos_sim.argsort()[:max_recommendations]


  #Εκτύπωση ID,cosine_distance,title,summary,categories
  for idx,ID in enumerate(indices.tolist()):
    if (ID == target_movie):
      print("Target movie")
    else:
      print(idx,"Recommended")
    print("ID:",ID)
    print("Cosine Distance:",cos_sim[ID])
    print("Title:",titles[ID])
    print("Summary",corpus[ID])
    
    with open('Recommendations.txt', 'a') as testwritefile:
      testwritefile.write(corpus[ID])
      testwritefile.write('\n')
      testwritefile.write('\n')
      testwritefile.write('\n')

    print("Categories",categories[ID])
    print("")

#Αποθηκευουμε ID-Κατηγορίες σε txt για καλύτερη ανάλυση
open('id_categories.txt', 'w').close()
with open('id_categories.txt', 'w') as f:
    for ID,category in enumerate(categories):
        f.write("%s %s\n" % (ID,category))

#Αποθηκευουμε ID-Τίτλο σε txt για καλύτερη ανάλυση
open('id_titles.txt', 'w').close()
with open('id_titles.txt', 'w') as f:
    for ID,title in enumerate(titles):
        f.write("%s %s\n" % (ID,title))

#Συνάρτηση η οποία εκτυπώνει για μια ταινία (ID)
#τους όρους με τις μεγαλύτερες τιμές tf_idf (φθίνουσα σειρά)
def print_tf_idf_for_movie(ID):
  df_new = df.sort_values(by=ID, axis=1,ascending =False).loc[[ID]] 
  df_new = df_new.drop(df_new.columns[df_new.eq(0).all()], axis=1)
  return df_new

"""## Baseline TfidfVectorizer"""

#Χωρίς παραμέτρους αρχικά
vectorizer = TfidfVectorizer()
vectorizer.fit(corpus)
corpus_tf_idf = vectorizer.transform(corpus).toarray() 
df = pd.DataFrame(corpus_tf_idf, columns = vectorizer.get_feature_names())

corpus_tf_idf_baseline = corpus_tf_idf

"""### 1<sup>o</sup> Παράδειγμα """

#Επιλέγουμε τυχαία μια ταινία απο το Dataset,
#και επιθυμούμε δυο προτάσεις


target_ID = 370
max_rec = 2

content_recomneder(target_ID,max_rec)

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 370 (target movie)
tf_idf_terms = print_tf_idf_for_movie(370)
tf_idf_terms

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 901 (1η προτεινόμενη)
tf_idf_terms= print_tf_idf_for_movie(901)
tf_idf_terms

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 1145 (2η προτεινόμενη)
tf_idf_terms= print_tf_idf_for_movie(1145)
tf_idf_terms

"""### 2<sup>o</sup> Παράδειγμα """

# Παρατηρούμε οτι στο dataset μας υπάρχουν οι ταινίες
# Men in black και Men in black 3. Θα εξετάσουμε αν με 
# baseline tf_idf_vectorize και είσοδο τη πρώτη , 
# παίρνουμε τη δεύτερη (Men in black 3) σαν πρόταση.

target_ID = 1492 
max_rec = 1

content_recomneder(target_ID,max_rec)

#Eκτυπώνουμς τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 1492 
tf_idf_terms = print_tf_idf_for_movie(1492)
tf_idf_terms

#Eκτυπώνουμς τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 850  
tf_idf_terms = print_tf_idf_for_movie(850)
tf_idf_terms

"""### Παρατηρήσεις

**Πρώτο Παράδειγμα**: <br> 
Παρατηρούμε ότι η δεύτερη προτεινόμενη ταινία δεν έχει παρόμοιο περιεχόμενο με την target movie. Πιο ειδικά, η ταινία-στόχος ανήκει στις κατηγορίες `["Action/Adventure",  "Zombie Film",  "Western",  "Horror"]`, ενώ οι προτεινόμενες στις κατηγορίες `["Short Film",  "Comedy", "Family Film", "Animation"]`. Αυτό συμβαίνει διότι (όπως φαίνεται και από τους τρεις παραπάνω πίνακες), τα τρία κείμενα έχουν τα εξής κοινά χαρακτηριστικά:

*   Ονόματα (πχ Elmer)
*   Άρθρα (πχ the, a, an)
*   Αντωνυμίες (πχ his, her, he, she)
*   Προθέσεις (πχ to, of, with, for, at, but)
*   Συνηθισμένοι όροι (πχ is, has, do)

Απο τα χαρακτηριστικά αυτά όμως οδηγούμαστε σε λάθος συμπεράσματα, καθώς δεν είναι αντιπροσωπευτικά της πλοκής των ταινιών. Οπότε θα πρέπει να αφαιρεθούν.
<br><br>
**Δεύτερο Παράδειγμα**: <br> 
Τα ίδια ισχύουν και για το δεύτερο παράδειγμα. Επίσης το σύστημα προτάσεων, για ταινία που επιλέξαμε σαν target movie (Men in Black), έπρεπε να προτείνει το *Men in Black 3* που υπάρχει στο dataset μας. Κάτι τέτοιο δεν πραγματοποιήθηκε για τους παραπάνω λόγους. Οπότε είναι αναγκαία η βελτιστοποίηση της `TfidfVectorizer`.

## Βελτιστοποίηση TfidfVectorizer

### Πειραματισμός με common words
"""

#Συνηθισμένες λέξεις στα αγγλικά
my_stop_words = text.ENGLISH_STOP_WORDS

#Ονόματα ανθρώπων 
names = [name.lower() for name in nltk.corpus.names.words()]

#Λέξεις που δηλώνουν κατάταξη (first,second ) 
numeric_data = [num2words.num2words(n, ordinal=True) for n in range(100)]

#Λέξεις που εμφανίζοντααι συχνά στις υποθέσεις των ταινιών
#αλλά δεν αντιπροσωπέυουν το περιεχόμενο
common_words = ['film','movie','people','person']


#Συνένωση όλων των παραπάνω σε μια λίστα 
cut_list = list(my_stop_words) + list(string.punctuation) + list(stopwords.words('english')) + names + numeric_data + common_words

"""### Πειραματισμός με Stemming-Lemmatization """

#Κλάση μέσω της οποίας θα κάνουμε Stemming
#στους όρους του corpus (Παράμετρος TfidfVectorizer())

class SnowBallTokenizer(object):
    def __init__(self):
        self.wnl = SnowballStemmer('english')
    def __call__(self, articles):
      lemmatized_tokens = []
      for t in word_tokenize(articles):
        if (t.isalpha() == True):                     #Aποκοπή Αριθμητικών Τιμών
          lemmatized_tokens.append(self.wnl.stem(t))
      return lemmatized_tokens

"""Αρχικά πειραματιστήκαμε με τη χρήση τόσο **Stemming** όσο και **Lemmatization**. Πιο ειδικά, παρατηρήσαμε ότι κάνοντας αφαίρεση κατάληξης (stemming) λέξεις όπως "*killing*", "*killed*" μετασχηματίζονται σε ένα κοινό όρο "*kill*". Κάτι τέτοιο είναι σημαντικό καθώς οι δυο παραπάνω λέξεις έχουν παρόμοια φυσική σημασία και πρέπει να μετηρθούν σαν μια λέξη. Άρα για το λόγο αυτό προτιμήσαμε αφαίρεση κατάληξης απο λημματοποίηση.<br>
Στην συνέχεια δοκιμάσαμε διάφορους stemmers, ώστε να καταλήξουμε στο καλύτερο δυνατό αποτέλεσμα. Ανάμεσα στους **Porter**, **Lancaster** και  **Snowball**, προτιμήσαμε τον τελευταίο. Ο Snowball (Porter 2) είναι κοινώς αποδεκτό ότι είναι μια βελτιωμένη έκδοση του Porter αλλά παράλληλα δεν είναι τόσο aggressive-strict όσο ο Lancaster.
"""

#1η Βελτιστοποίηση TfidfVectorizer (Πειραματισμός με common words - stemmers)
vectorizer = TfidfVectorizer(tokenizer=SnowBallTokenizer(),stop_words = cut_list)
vectorizer.fit(corpus)
corpus_tf_idf = vectorizer.transform(corpus).toarray()
df = pd.DataFrame(corpus_tf_idf, columns = vectorizer.get_feature_names())

corpus_tf_idf_common_words = corpus_tf_idf

"""Αφού βελτιστοποιήσαμε την `TfidfVectorizer`, ξανατρέχουμε την συνάρτηση `content_recommender`, για τις ίδιες ταινίες. Στη συνέχεια τυπώνουμε τα `tf_idf_terms` για να δούμε ποιες λέξεις αφαιρέθηκαν.

#### 1<sup>o</sup> Παράδειγμα
"""

target_ID = 370
max_rec = 2

content_recomneder(target_ID,max_rec)

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 370  
tf_idf_terms = print_tf_idf_for_movie(370)
tf_idf_terms

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 4113
tf_idf_terms= print_tf_idf_for_movie(4113)
tf_idf_terms

#Eκτυπώνουμε τους όρους με το μεγαλύτερο tf_idf για την ταινία με ID = 936 
tf_idf_terms= print_tf_idf_for_movie(936)
tf_idf_terms

"""#### 2<sup>o</sup> Παράδειγμα """

target_ID = 1492 
max_rec = 1

content_recomneder(target_ID,max_rec)

"""#### Παρατηρήσεις

Αφαιρέσαμε από τις πλοκές των τανιών τα παρακάτω:
*   Συνηθισμένες λέξεις στα αγγλικά
*   Ονόματα ανθρώπων
*   Αριθμητικές τιμές
*   Λέξεις που δηλώνουν κατάταξη
*   Λέξεις που εμφανίζοντααι συχνά στις υποθέσεις των ταινιών αλλά δεν αντιπροσωπέυουν το περιεχόμενο

Ξανατρέξαμε την συνάρτηση `content_recommender`, για τα δύο ίδια παραδείγματα που είχαμε τρέξει και στο basiline.
<br> <br> 
**Πρώτο Παράδειγμα**: <br> 
Αυτή τη φορά, παρατηρούμε ότι το σύστημα προτάσεων, πρότεινε ταινίες με αρκετά παρόμοιο περιεχόμενο συγκριτικά με την target_movie. Συγκεκριμένα, για την ταινία στόχο που ανήκει στις κατηγορίες `["Action/Adventure",  "Zombie Film",  "Western",  "Horror"]`, πρότεινε δύο ταινίες που ανήκουν στις κατηγορίες `["Action",  "Horror", "Zombie Film"]`. Αυτό συνέβη διότι, τώρα οι λέξεις με την μεγαλύτερη συμμετοχή στην απόφαση δεν είναι ονόματα, αντωνυμίες, common words και άρθρα, αλλά λέξεις αντιπροσωπευτικές με το περιεχόμενο όπως zombie, kill, escape, attack. 
<br> <br> 
**Δεύτερο Παράδειγμα**: <br> 
Παρόμοια αποτελέσματα πατατηρούμε και στο δεύτερο παράδειγμα. Αυτή τη φορά, το σύστημα προτάσεων για την ταινία στόχο "Men in Black", πρότεινε σαν πρώτο recommended το sequel "Men in Black 3" που υπάρχει στο dataset μας, γεγονός που φανερώνει μια σημαντική βελτιστοποίηση στην `TfidfVectorizer`.

### Πειραματισμός με παραμέτρους min_df, max_df

Στο σημείο αυτό, προκειμένου να προσδιορίσουμε τις κατάλληλες τιμές στις παραμέτρους `max_df`, `min_df`, επιλέξαμε τυχαία 5 ταινίες απο διαφορετικές κατηγορίες (Romantic, Drama, Action, Comedy, Thriller).Για κάθε ταινία τυπώναμε 5 προτάσεις. Στη συνέχεια, αφού διαβάζαμε τις πλοκές αλλά και τις επιμέρους κατηγορίες σημειώναμε πόσες προτάσεις ήταν αντιπροσωπευτικές. Στην συνέχεια μεταβάλλαμε τις τιμές `max_df`, `min_df` και για τις ίδες ταινίες παρατηρούσαμε την επιτυχία των προτάσεων.(Σταματήσαμε όταν για όλες τις ταινίες απο τα πέντε είδη, πήραμε ικανοποιητικά αποτελέσματα).Tα αποτελέσματα συνοψίζονται στον ακόλουθο πίνακα.

![Screenshot from 2020-12-14 13-58-32.png](data:image/png;base64,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)

Όπως φαίνεται και απο τον παραπάνω πίνακα, οι τιμές `max_df = 0.7`, `min_df = 100`, δώσανε τα καλύτερα αποτελέσματα στο σύνολο των (25) ταινιών. Με άλλα λόγια, επιλέξαμε να αποκόψουμε τους όρους που εμφανίζονται σε  λιγότερες απο 100 υποθέσεις καθώς και τους όρους που συναντώνται σε περισσότερες απο 3500 (`= 0.7 * 5000 `) υποθέσεις.
"""

#2η Βελτιστοποίηση TfidfVectorizer (Πειραματισμός με common words,stemmers και max_df,min_df)
vectorizer = TfidfVectorizer(stop_words = cut_list, tokenizer=SnowBallTokenizer(),max_df=0.7, min_df= 100)
vectorizer.fit(corpus)
corpus_tf_idf = vectorizer.transform(corpus).toarray()

corpus_tf_idf_final = corpus_tf_idf

"""## Παραδείγματα Προτάσεων

Στο σημείο αυτό παρουσιάζουμε για 10 ταινίες απο διαφορετικά είδη, 5 προτάσεις. Καλώντας κάθε φορά την συνάρτηση `content_recomneder`, ανοίγουμε το `Recommendations.txt` που δημιουργείται, και σημειώνουμε σε Τext Cell τα κοινά σημεία των υποθέσεων.

### Drama
"""

#Drama
target_ID = 4548
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Όλες οι παραπάνω ταινίες ανήκουν στην κατηγορία **"Drama"**. Ως προς το περιεχόμενο μπορεί κανείς να παρατηρήσει τις εξής κοινές λέξεις: family, mother, women, husband, friends, children, calls, kill, apology, suspicious.

### Romance Film
"""

#Romnace
target_ID = 2943
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Όλες οι παραπάνω ταινίες ανήκουν στην κατηγορία **Romantic Drama / Romance Film**,εκτός απο τη 2η και τη 5η προτεινόμενη που ειναι **"Japanese Movie"** και **"Drama"**. Βέβαια η πρώτη εξ αυτών, αν και Japanese Movie, πραγματεύεται τη ζωή μιας γυναίκας που ερωτεύεται και τέλος πέφτει θύμα παθολογικής ζήλιας του άντρα της.Η δεύτερη εξ αυτών αν και Drama, αναφέρεται σε μια γυναίκα που επιστρέφει μετά απο χρόνια στο πατρικό της, ξετυλίγοντας τη ζωή της.  Ως προς το περιεχόμενο μπορεί κανείς να παρατηρήσει τις εξής κοινές λέξεις: love, refuse, accept, relationship, marry, man, girl pregnant.

### Thriller
"""

#Thriller
target_ID = 1
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Όλες οι παραπάνω ταινίες ανήκουν στην κατηγορία **"Τhriller"**, εκτός απο τη 3η προτεινόμενη που είναι **Drama**. Η κατάταξη αυτή οφείλεται στο γεγονός ότι αυτή η ταινία έχει πολλούς κοινούς όρους με τις ταινίες Thriller (alive, commit κλπ). Στις υπόλοιπες ταινίες κοινό παρανομαστή αποτελούν οι λέξεις: escape, kill, murder, survive, disaster, run, police, die, fight.

### Action - Adventure
"""

#Adventure
target_ID = 370
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες οι δυο πρώτες ανήκουν στην κατηγορία **"Action\Adventure"**,όπως και η target_movie, ενώ οι υπόλοιπες είναι **"Horror"** (που αποτελεί και αυτή κατηγορία της target). Κοινοί άξονες στις ταινίες αυτές είναι οι λέξεις: zombie, attack, fight, steel, escape, kill, soldier, army, police, knife.

### Comedy
"""

#Comedy 
target_ID = 162
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Απο τις παραπάνω ταινίες είναι **Comedy** εκτός απο τις δυο πρώτες. προτάσεις Η πρώτη εξ αυτών συνδέεται με τη target movie με την κατηγορία **Family Film** και **Short Film**. Η δεύτερη αν και δραματικού περιεχομένου περιέχει κοινούς όρους με τις υπόλοιπες ταινίες. Οι όροι που συναντώνται γενικώς συχνά είναι λέξεις όπως "tries" (σε όλες τις υποθέσεις) που υποδηλωνούν προσπάθεια των ηρώων να σκαρφιστούν (!) κάποιο σχέδιο, καθώς και λέξεις όπως "think" που αντικατοπτρίζουν τις αντιλήψεις-σκέψεις των ηρώων κατα την υλοποίηση του.

### Science Fiction
"""

#Science Fiction - Men in Black 
target_ID = 1492
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες, όλες ανήκουν στην κατηγορία **"Science Fiction"**, όπως και η target_movie, εκτός από την πρώτη, η οποία είναι κατηγορίας "Drama". Αυτό συμβαίνει διότι, όπως παρατηρήσαμε από το αρχείο Recommendations.txt, έχουν αρκετά κοινό περιεχόμενο με επαναλαμβανόμενες λέξεις όπως: alien, gun, agent, κτλ. Γενικά σε όλες τις ταινίες, κοινοί άξονες είναι οι προηγούμενες και επιπλέον οι λέξεις: earth, war, battle, secret, plan, κτλ.

### Musical
"""

#Musical
target_ID = 156
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες, όλες ανήκουν στην κατηγορία **"Musical"**, όπως και η target_movie, εκτός από την τέρτατη, η οποία είναι κατηγορίας "Documentary". Αυτό συμβαίνει διότι, όπως παρατηρήσαμε από το αρχείο Recommendations.txt, το συγκεκριμένο documentary έχει μουσικό περιοχόμενο. Γενικά σε όλες τις ταινίες, κοινοί άξονες είναι οι λέξεις: music, musical, sing, dance κτλ.

### Crime Fiction
"""

#Crime Fiction 
target_ID = 4947
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες, όλες ανήκουν στην κατηγορία **"Crime Fiction"**, όπως και η target_movie. Kοινοί άξονες είναι οι λέξεις: robbery, prison, murder, crime, κτλ.

### War Film
"""

#War film
target_ID = 528
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες, όλες ανήκουν στην κατηγορία **"War Film"**, όπως και η target_movie, εκτός από την τελευταία, η οποία είναι κατηγορίας "Propaganda Film". Αυτό συμβαίνει διότι, όπως παρατηρήσαμε από το αρχείο Recommendations.txt, η συγκεκριμένη ταινία έχει παρόμοιο περιοχόμενο (λέξεις) με την target_movie. Γενικά σε όλες τις ταινίες, κοινοί άξονες είναι οι λέξεις: battle, soldier, war, kill, fight, army κτλ.

### Horror Film
"""

#Horror 
target_ID = 94
max_rec = 5

content_recomneder(target_ID,max_rec)

"""Παρατηρήσεις: Aπο τις παραπάνω προτεινόμενες ταινίες, όλες ανήκουν στην κατηγορία **"Horror"**, όπως και η target_movie, εκτός από την τρίτη, η οποία είναι κατηγορίας "Silent Film". Αυτό συμβαίνει διότι, όπως παρατηρήσαμε από το αρχείο Recommendations.txt, η συγκεκριμένη ταινία έχει παρόμοιο περιοχόμενο (λέξεις) με την target_movie όπως: blood, night, vampire, escape, kill, κτλ. Γενικά σε όλες τις ταινίες, κοινοί άξονες είναι οι λέξεις: ghost, kill, death, blood, night(mare), escape, cry κτλ.

# Εφαρμογή 2.  Τοπολογική και σημασιολογική απεικόνιση της ταινιών με χρήση SOM
<img src="https://i.imgur.com/Z4FdurD.jpg" width="60%">

## Δημιουργία dataset
Στη δεύτερη εφαρμογή θα βασιστούμε στις τοπολογικές ιδιότητες των Self Organizing Maps (SOM) για να φτιάξουμε ενά χάρτη (grid) δύο διαστάσεων όπου θα απεικονίζονται όλες οι ταινίες της συλλογής της ομάδας με τρόπο χωρικά συνεκτικό ως προς το περιεχόμενο και κυρίως το είδος τους (ο παραπάνω χάρτης είναι ενδεικτικός, δεν αντιστοιχεί στο dataset μας). 

Η `build_final_set` αρχικά μετατρέπει την αραιή αναπαράσταση tf-idf της εξόδου της `TfidfVectorizer()` σε πυκνή (η [αραιή αναπαράσταση](https://en.wikipedia.org/wiki/Sparse_matrix) έχει τιμές μόνο για τα μη μηδενικά στοιχεία). 

Στη συνέχεια ενώνει την πυκνή `dense_tf_idf` αναπαράσταση και τις binarized κατηγορίες `catbins` των ταινιών ως επιπλέον στήλες (χαρακτηριστικά). Συνεπώς, κάθε ταινία αναπαρίσταται στο Vector Space Model από τα χαρακτηριστικά του TFIDF και τις κατηγορίες της.

Τέλος, δέχεται ένα ορισμα για το πόσες ταινίες να επιστρέψει, με default τιμή όλες τις ταινίες (5000). Αυτό είναι χρήσιμο για να μπορείτε αν θέλετε να φτιάχνετε μικρότερα σύνολα δεδομένων ώστε να εκπαιδεύεται ταχύτερα το SOM.
"""

def build_final_set(doc_limit = 5000, tf_idf_only=False):
    # convert sparse tf_idf to dense tf_idf representation
    dense_tf_idf = corpus_tf_idf[0:doc_limit,:]
    if tf_idf_only:
        # use only tf_idf
        final_set = dense_tf_idf
    else:
        # append the binary categories features horizontaly to the (dense) tf_idf features
        final_set = np.hstack((dense_tf_idf, catbins[0:doc_limit,:]))
        # η somoclu θέλει δεδομένα σε float32
    return np.array(final_set, dtype=np.float32)

final_set = build_final_set()

"""Τυπώνουμε τις διαστάσεις του τελικού dataset μας. Χωρίς βελτιστοποίηση του TFIDF θα έχουμε περίπου 50.000 χαρακτηριστικά."""

print("Baseline corpus_tf_idf:                         ",corpus_tf_idf_baseline.shape)
print("Χωρίς common words corpus_tf_idf:               ",corpus_tf_idf_common_words.shape)
print("Βελτιστοποιημένο corpus_tf_idf χωρίς κατηγορίες:",corpus_tf_idf.shape)
print("Βελτιστοποιημένο corpus_tf_idf με κατηγορίες:   ",final_set.shape)

"""Παρατηρούμε από τους παραπάνω πίνακες ότι από τα αρχικά 48709 χαρακτηριστικά του corpus_tf_idf, μετά την βελτιστοποίηση και την εισαγωγή των κατηγοριών, έχουμε συνολικά **1340** χαρακτηριστικά. Με βάση την εμπειρία μας στην προετοιμασία των δεδομένων στην επιβλεπόμενη μάθηση, γνωρίζουμε ότι έχουν ήδη αφαιρεθεί πολλά χαρακτηριστικά οπότε δεν είναι αναγκαίο κάποιο επιπλέον βήμα προεπεξεργασίας (*Όπως PCA, Variance Threshold κτλ.*)

## Εκπαίδευση χάρτη SOM

Θα δουλέψουμε με τη βιβλιοθήκη SOM ["Somoclu"](http://somoclu.readthedocs.io/en/stable/index.html). Εισάγουμε τις somoclu και matplotlib και λέμε στη matplotlib να τυπώνει εντός του notebook (κι όχι σε pop up window).

Δουλέψαμε με χάρτη τύπου planar, παραλληλόγραμμου σχήματος νευρώνων με τυχαία αρχικοποίηση (όλα αυτά είναι default). Δοκιμάσαμε διάφορα μεγέθη χάρτη ωστόσο όσο ο αριθμός των νευρώνων μεγαλώνει, μεγαλώνει και ο χρόνος εκπαίδευσης. Για το training δεν ξεπεράσαμε τα 100 epochs. Χρησιμοποιήσαμε την `time` για να έχουμε μια εικόνα των χρόνων εκπαίδευσης. Ενδεικτικά, με σωστή κωδικοποίηση tf-idf, μικροί χάρτες για λίγα δεδομένα (1000-2000) παίρνουν γύρω στο ένα λεπτό ενώ μεγαλύτεροι χάρτες με όλα τα δεδομένα μπορούν να πάρουν 10-15 λεπτά ή και περισσότερο.
"""

# Commented out IPython magic to ensure Python compatibility.
# Αρχικοποίηση χάρτη SOM
n_rows, n_columns = 10, 10
som = somoclu.Somoclu(n_columns, n_rows, compactsupport=False)

# Εκπαίδευση χάρτη SOM και εκτύπωση χρόνου
# %time som.train(final_set, epochs=100)

"""
## Best matching units

Μετά από κάθε εκπαίδευση αποθηκεύσαμε σε μια μεταβλητή τα best matching units (bmus) για κάθε ταινία. Τα bmus μας δείχνουν σε ποιο νευρώνα ανήκει η κάθε ταινία. Προσοχή: η σύμβαση των συντεταγμένων των νευρώνων είναι (στήλη, γραμμή) δηλαδή το ανάποδο από την Python. Με χρήση της [np.unique](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html) (μια πολύ χρήσιμη συνάρτηση στην άσκηση) αποθηκεύσαμε τα μοναδικά best matching units και τους δείκτες τους (indices) προς τις ταινίες. Παρατηρήσαμε ότι μπορεί να έχουμε λιγότερα μοναδικά bmus από αριθμό νευρώνων γιατί μπορεί σε κάποιους νευρώνες να μην έχουν ανατεθεί ταινίες. Ως αριθμό νευρώνα θεωρήσαμε τον αριθμό γραμμής στον πίνακα μοναδικών bmus.
"""

bmus = som.bmus

print("bmus:   ",bmus.shape)

# Μοναδικά bmus
# το return_inverse επιστρέφει και τους δείκτες indices
ubmus, indices = np.unique(bmus, return_inverse=True, axis=0)

print("ubmus:  ",ubmus.shape)
print("indices:",indices.shape)

#Παράδειγμα (Θα φύγει!!!!!!!!!!!!)
print("Ο νευρώνας που ανήκει η ταινία με ID = 1 είναι ο",bmus[1],"με αριθμό μοναδικού νευρώνα", indices[1])
ubmus[28]

"""
## Ομαδοποίηση (clustering)

Τυπικά, η ομαδοποίηση σε ένα χάρτη SOM προκύπτει από το unified distance matrix (U-matrix): για κάθε κόμβο υπολογίζεται η μέση απόστασή του από τους γειτονικούς κόμβους. Εάν χρησιμοποιηθεί μπλε χρώμα στις περιοχές του χάρτη όπου η τιμή αυτή είναι χαμηλή (μικρή απόσταση) και κόκκινο εκεί που η τιμή είναι υψηλή (μεγάλη απόσταση), τότε μπορούμε να πούμε ότι οι μπλε περιοχές αποτελούν clusters και οι κόκκινες αποτελούν σύνορα μεταξύ clusters.

To somoclu δίνει την επιπρόσθετη δυνατότητα να κάνουμε ομαδοποίηση των νευρώνων χρησιμοποιώντας οποιονδήποτε αλγόριθμο ομαδοποίησης του scikit-learn. Στην άσκηση χρησιμοποιήσαμε τον k-Means. Για τον αρχικό μας χάρτη δοκιμάσαμε ένα k=20. 
"""

# Ομαδοποίηση των νευρώνων χρησιμοποιώντας τον k-Means
k = 20
algorithm = KMeans(n_clusters=k)
som.cluster(algorithm=algorithm)

clusters = np.reshape(algorithm.labels_, (n_rows, n_columns))

"""## Αποθήκευση του SOM

Επειδή η αρχικοποίηση του SOM γίνεται τυχαία και το clustering είναι και αυτό στοχαστική διαδικασία, οι θέσεις και οι ετικέτες των νευρώνων και των clusters θα είναι διαφορετικές κάθε φορά που τρέχουμε τον χάρτη, ακόμα και με τις ίδιες παραμέτρους. Για να αποθηκεύσουμε ένα συγκεκριμένο som και clustering χρησιμοποιήσαμε και πάλι την `joblib`.

## Οπτικοποίηση U-matrix, clustering και μέγεθος clusters

Για την εκτύπωση του U-matrix χρησιμοποιήσαμε τη `view_umatrix` με ορίσματα `bestmatches=True` και `figsize=(15, 15)` ή `figsize=(20, 20)`. Τα διαφορετικά χρώματα που εμφανίζονται στους κόμβους αντιπροσωπεύουν τα διαφορετικά clusters που προκύπτουν από τον k-Means. 

Για μια δεύτερη πιο ξεκάθαρη οπτικοποίηση του clustering τυπώνουμε απευθείας τη μεταβλητή `clusters`.

Τέλος, χρησιμοποιώντας πάλι την `np.unique` (με διαφορετικό όρισμα) και την `np.argsort` (υπάρχουν και άλλοι τρόποι υλοποίησης) εκτυπώνουμε τις ετικέτες των clusters (αριθμοί από 0 έως k-1) και τον αριθμό των νευρώνων σε κάθε cluster, αύξουσα σειρά ως προς τον αριθμό των νευρώνων. 

Ακολουθεί ένα μη βελτιστοποιημένο παράδειγμα για τις τρεις προηγούμενες εξόδους:

<img src="https://image.ibb.co/i0tsfR/umatrix_s.jpg" width="35%">
<img src="https://image.ibb.co/nLgHEm/clusters.png" width="35%">
"""

# Τυπώνουμε απευθείας τη μεταβλητή clusters
print(clusters)

# Εκτύπωση του U-matrix
som.view_umatrix(bestmatches=True, colorbar=True, figsize=(15, 15))

# Ταξινόμηση κατά αύξουσα σειρά ως προς τον αριθμό των νευρώνων
counts = collections.Counter(algorithm.labels_)
test = sorted(counts.items(), key = lambda kv:(kv[1], kv[0]))

# Εκτυπώνομυε τις ετικέτες των clusters (αριθμοί από 0 έως k-1) 
# και τον αριθμό των νευρώνων σε κάθε cluster, 
# με αύξουσα σειρά ως προς τον αριθμό των νευρώνων.
print("Clusters sorted by increasing number of neurons:")
print("Cluster index")
print("Number of neurons")
print(np.reshape([[x[0] for x in test], [x[1] for x in test]], (-1,k)))

"""
## Σημασιολογική ερμηνεία των clusters

Προκειμένου να μελετήσουμε τις τοπολογικές ιδιότητες του SOM και το αν έχουν ενσωματώσει σημασιολογική πληροφορία για τις ταινίες διαμέσου της διανυσματικής αναπαράστασης με το tf-idf και των κατηγοριών, χρειαζόμαστε ένα κριτήριο ποιοτικής επισκόπησης των clusters. Θα υλοποιήσουμε το εξής κριτήριο: Λαμβάνουμε όρισμα έναν αριθμό (ετικέτα) cluster. Για το cluster αυτό βρίσκουμε όλους τους νευρώνες που του έχουν ανατεθεί από τον k-Means. Για όλους τους νευρώνες αυτούς βρίσκουμε όλες τις ταινίες που τους έχουν ανατεθεί (για τις οποίες αποτελούν bmus). Για όλες αυτές τις ταινίες τυπώνουμε ταξινομημένη τη συνολική στατιστική όλων των ειδών (κατηγοριών) και τις συχνότητές τους. Αν το cluster διαθέτει καλή συνοχή και εξειδίκευση, θα πρέπει κάποιες κατηγορίες να έχουν σαφώς μεγαλύτερη συχνότητα από τις υπόλοιπες. Θα μπορούμε τότε να αναθέσουμε αυτήν/ές την/τις κατηγορία/ες ως ετικέτες κινηματογραφικού είδους στο cluster.

Η συνάρτηση αυτή υλοποιήθηκε ως εξής:

1. Ορίζουμε συνάρτηση `print_categories_stats` που δέχεται ως είσοδο λίστα με ids ταινιών. Δημιουργούμε μια κενή λίστα συνολικών κατηγοριών. Στη συνέχεια, για κάθε ταινία επεξεργαζόμαστε το string `categories` ως εξής: δημιουργούμε μια λίστα διαχωρίζοντας το string κατάλληλα με την `split` και αφαιρούμε τα whitespaces μεταξύ ετικετών με την `strip`. Προσθέτουμε τη λίστα αυτή στη συνολική λίστα κατηγοριών με την `extend`. Τέλος χρησιμοποιούμε πάλι την `np.unique` για να μετρήσουμε συχνότητα μοναδικών ετικετών κατηγοριών και ταξινομούμε με την `np.argsort`. Τυπώνουμε τις κατηγορίες και τις συχνότητες εμφάνισης ταξινομημένα.

2. Ορίζουμε τη βασική μας συνάρτηση `print_cluster_neurons_movies_report` που δέχεται ως όρισμα τον αριθμό ενός cluster. Με τη χρήση της `np.where` μπορούμε να βρούμε τις συντεταγμένες των bmus που αντιστοιχούν στο cluster και με την `column_stack` να φτιάξουμε έναν πίνακα bmus για το cluster. Για κάθε bmu αυτού του πίνακα ελέγχουμε αν υπάρχει στον πίνακα μοναδικών bmus που έχουμε υπολογίσει στην αρχή συνολικά και αν ναι προσθέτουμε το αντίστοιχο index του νευρώνα σε μια λίστα. 

3. Υλοποιούμε μια βοηθητική συνάρτηση `neuron_movies_report`. Λαμβάνει ένα σύνολο νευρώνων από την `print_cluster_neurons_movies_report` και μέσω της `indices` φτιάχνει μια λίστα με το σύνολο ταινιών που ανήκουν σε αυτούς τους νευρώνες. Στο τέλος καλεί με αυτή τη λίστα την `print_categories_stats` που τυπώνει τις στατιστικές των κατηγοριών.

Θα επιτελούμε τη σημασιολογική ερμηνεία του χάρτη καλώντας την `print_cluster_neurons_movies_report` με τον αριθμός ενός cluster που μας ενδιαφέρει. 

Παράδειγμα εξόδου για ένα cluster (μη βελτιστοποιημένος χάρτης, ωστόσο βλέπετε ότι οι μεγάλες κατηγορίες έχουν σημασιολογική  συνάφεια):

```
Overall Cluster Genres stats:  
[('"Horror"', 86), ('"Science Fiction"', 24), ('"B-movie"', 16), ('"Monster movie"', 10), ('"Creature Film"', 10), ('"Indie"', 9), ('"Zombie Film"', 9), ('"Slasher"', 8), ('"World cinema"', 8), ('"Sci-Fi Horror"', 7), ('"Natural horror films"', 6), ('"Supernatural"', 6), ('"Thriller"', 6), ('"Cult"', 5), ('"Black-and-white"', 5), ('"Japanese Movies"', 4), ('"Short Film"', 3), ('"Drama"', 3), ('"Psychological thriller"', 3), ('"Crime Fiction"', 3), ('"Monster"', 3), ('"Comedy"', 2), ('"Western"', 2), ('"Horror Comedy"', 2), ('"Archaeology"', 2), ('"Alien Film"', 2), ('"Teen"', 2), ('"Mystery"', 2), ('"Adventure"', 2), ('"Comedy film"', 2), ('"Combat Films"', 1), ('"Chinese Movies"', 1), ('"Action/Adventure"', 1), ('"Gothic Film"', 1), ('"Costume drama"', 1), ('"Disaster"', 1), ('"Docudrama"', 1), ('"Film adaptation"', 1), ('"Film noir"', 1), ('"Parody"', 1), ('"Period piece"', 1), ('"Action"', 1)]```
   """

# Συνάρτηση που δέχεται ως είσοδο λίστα με ids ταινιών
# και τυπώνει τις κατηγορίες και τις συχνότητες εμφάνισης ταξινομημένα

def print_categories_stats(id_list):
  
  # Αρχικοποίηση λίστας συνολικών κατηγοριών
  total_categ = []
  
  # Για κάθε ID διαχωρίζει τις κατηγορίες και τις προσθέτει στην τελική λίστα
  for i in id_list:
    belongs_to=categories[i][0].replace("  ","").split(',')
    for j in belongs_to:
      total_categ.append(j)
  
  # Αθροίζει και έπειτα ταξινομεί τις συνολικές κατηγορίες κατά φθίνουσα σειρά
  counts = collections.Counter(total_categ)
  sort = sorted(counts.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)
  
  # Εκτύπωση ταξινομημένων κατηγοριών και συχνοτήτων
  print(sort)

# Συνάρτηση που δέχεται ως όρισμα τον αριθμό ενός cluster
# και επιστρέφει μια λίστα με τους νευρώνες που αντιστοιχούν σε αυτό το cluster

def print_cluster_neurons_movies_report(clust_numb):
  
  # Αρχικοποίηση τελικής λίστας νευρώνων
  neuro_list =[]
  
  # Εντοπισμός συνεταγμένων νευρώνων [στήλη,γραμμή]
  result = np.where(clusters==clust_numb)
  listOfCoordinates = list(zip(result[1], result[0]))
  
  # Για κάθε νερώνα ελέγχει αν υπάρχει στον πίνακα μοναδικών bmus (ubmus)
  # και αν ναι, τον προσθέτει στην τελική λίστα νευρώνων
  for cord in listOfCoordinates:
    if ([cord[0],cord[1]] in ubmus.tolist()):
      neuro_list.append([cord[0],cord[1]])
  
  # Επιστρέφει τη τελική λίστα με τους νευρώνες, που αντιστοιχούν στο cluster εισόδου
  return (neuro_list)

# Συνάρτηση που δέχεται ως όρισμα τον αριθμό ενός cluster,
# και τυπώνει τις κατηγορίες ταινιών και τις συχνότητες εμφάνισης ταξινομημένα

def neuron_movies_report(clust_numb):
  
  # Αρχικοποίηση λίστας με ID
  id_list = []
 
  # Bρίσκει τους νευρώνες που αντιστοιχούν στο cluster εισόδου,
  # μέσω της συνάρτησης "print_cluster_neurons_movies_report"
  for neuro in print_cluster_neurons_movies_report(clust_numb):
    
    # Βρίσκει και τοποθετεί στην λίστα τα ID των ταινιών του συγκεκριμένου νευρώνα
    for i, x in enumerate(bmus.tolist()):
      if (x == neuro):
        id_list.append(i)
  
  # Τυπώνει κατηγορίες και συχνότητες μεσω της συνάρτησης "print_categories_stats"
  print_categories_stats(id_list)

"""Σημασιολογική ερμηνεία του χάρτη 10 x 10:<br>
Επιλέγουμε τα clusters οι νευρώνες των οποίων βρίσκονται πιο κοντά (ανοιχτό χρώμα) στον U-Matrix
"""

print("Cluster 3:")
neuron_movies_report(3)
print("")
print("Cluster 5:")
neuron_movies_report(5)
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("Cluster 9:")
neuron_movies_report(9)
print("")
print("Cluster 11:")
neuron_movies_report(11)
print("")
print("Cluster 13:")
neuron_movies_report(13)

"""Παρατηρούμε ότι τα clusters με την καλύτερη σημασιολογική ερμηνεία, όσο αναφορά τις κατηγορίες, είναι το 3 και το 8. Αυτό διότι η πρώτη κατηγορία έχει αρκετά περισσότερες ταινίες συγκριτικά με τις υπόλοιπες. Σχετικά με τα υπόλοιπα clusters,  οι συχνότητες στις πρώτες κατηγορίες είναι παρόμοιες γεγονός που οφείλεται στο είδος. (πχ "Thriller" με "Crime Fiction" στο cluster 5 και "Romance Film" με "Romantic drama" στο cluster 9). Από την άλλη, θα μπορούσαμε να έχουμε περισσότερα clusters και νευρώνες για μια καλύτερη απεικόνιση των αποτελεσμάτων.

## Βελτιστοποίηση SOM
"""

# Commented out IPython magic to ensure Python compatibility.
# Δημιοργία - Εκπαίδευση χάρτη SOM και επιστροφήή bmus
def train_som (n_rows, n_columns):
  som = somoclu.Somoclu(n_columns, n_rows, compactsupport=False)

  # Εκπαίδευση χάρτη SOM και εκτύπωση χρόνου
#   %time som.train(final_set, epochs=100)

  bmus = som.bmus
  ubmus, indices = np.unique(bmus, return_inverse=True, axis=0)

  return som, bmus, ubmus, indices

# Ομαδοποίηση (clustering), Oπτικοποίηση U-matrix, clustering και μέγεθος clusters
def clusters_report(k, som):

  algorithm = KMeans(n_clusters=k)
  som.cluster(algorithm=algorithm)
  
  clusters = np.reshape(algorithm.labels_, (n_rows, n_columns))

  # Τυπώνουμε απευθείας τη μεταβλητή clusters ή την αππθηκεύουμε σε αρχείο
  if (n_rows >= 25):
    open('Clusters.txt', 'w').close()

    np.savetxt('Clusters.txt', clusters, fmt='%2d')
    
    print("Για καλύτερη ανάγνωση, ο πίνακας των clusters αποθηκεύεται στο αρχείο Clusters.txt")
  
  else:
    print(clusters)

  # Εκτύπωση του U-matrix
  som.view_umatrix(bestmatches=True, colorbar=True, figsize=(15, 15))

  # Ταξινόμηση κατά αύξουσα σειρά ως προς τον αριθμό των νευρώνων
  counts = collections.Counter(algorithm.labels_)
  test = sorted(counts.items(), key = lambda kv:(kv[1], kv[0]))

  # Εκτυπώνομυε τις ετικέτες των clusters (αριθμοί από 0 έως k-1) 
  # και τον αριθμό των νευρώνων σε κάθε cluster, 
  # με αύξουσα σειρά ως προς τον αριθμό των νευρώνων.
  print("Clusters sorted by increasing number of neurons:")
  print("Cluster index")
  print("Number of neurons")
  print(np.reshape([[x[0] for x in test], [x[1] for x in test]], (-1,k)))

  return clusters

"""### Grid 20 x 20 

"""

n_columns = 20
n_rows = 20
som, bmus, ubmus, indices = train_som(n_columns, n_rows)

"""#### n_clusters = 20"""

clusters = clusters_report(20, som)

print("Περιοχή Ι")
print("")
print("Cluster 1:")
neuron_movies_report(1)
print("")
print("Cluster 19:")
neuron_movies_report(19)
print("")
print("")
print("Περιοχή IΙ")
print("")
print("Cluster 18:")
neuron_movies_report(18)
print("")
print("")
print("Περιοχή III")
print("")
print("Cluster 2:")
neuron_movies_report(2)
print("")
print("Cluster 14:")
neuron_movies_report(14)
print("")
print("")
print("Περιοχή IV")
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("")
print("Περιοχή V")
print("")
print("Cluster 15:")
neuron_movies_report(15)
print("")
print("Cluster 6:")
neuron_movies_report(6)
print("")
print("Cluster 3:")
neuron_movies_report(3)
print("")
print("")
print("Περιοχή VI")
print("")
print("Cluster 4:")
neuron_movies_report(4)

"""#### n_clusters = 30"""

clusters = clusters_report(30, som)

print("Περιοχή Ι")
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("Cluster 27:")
neuron_movies_report(27)
print("")
print("")
print("Περιοχή II")
print("")
print("Cluster 14:")
neuron_movies_report(14)
print("")
print("Cluster 26:")
neuron_movies_report(26)
print("")
print("Cluster 0:")
neuron_movies_report(0)
print("")
print("")
print("Περιοχή IIΙ")
print("")
print("Cluster 20:")
neuron_movies_report(20)
print("")
print("")
print("Περιοχή IV")
print("")
print("Cluster 1:")
neuron_movies_report(1)
print("")
print("Cluster 10:")
neuron_movies_report(10)
print("")
print("")
print("Περιοχή V")
print("")
print("Cluster 9:")
neuron_movies_report(9)
print("")
print("")
print("Περιοχή VI")
print("")
print("Cluster 5:")
neuron_movies_report(5)

"""### Grid 25 x 25 """

n_columns = 25
n_rows = 25
som, bmus, ubmus, indices = train_som(n_columns, n_rows)

"""#### n_clusters = 25"""

clusters = clusters_report(25, som)

print("Περιοχή Ι")
print("")
print("Cluster 7:")
neuron_movies_report(7)
print("")
print("Cluster 21:")
neuron_movies_report(21)
print("")
print("")
print("Περιοχή II")
print("")
print("Cluster 6:")
neuron_movies_report(6)
print("")
print("Cluster 22:")
neuron_movies_report(22)
print("")
print("Cluster 3:")
neuron_movies_report(3)
print("")
print("")
print("Περιοχή III")
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("Cluster 9:")
neuron_movies_report(9)
print("")
print("")
print("Περιοχή IV")
print("")
print("Cluster 13:")
neuron_movies_report(13)
print("")
print("Cluster 16:")
neuron_movies_report(16)
print("")
print("")
print("Περιοχή V")
print("")
print("Cluster 4:")
neuron_movies_report(4)
print("")
print("Cluster 2:")
neuron_movies_report(2)

"""#### n_clusters = 30"""

clusters = clusters_report(30, som)

print("Περιοχή Ι")
print("")
print("Cluster 19:")
neuron_movies_report(19)
print("")
print("")
print("Περιοχή ΙI")
print("")
print("Cluster 12:")
neuron_movies_report(12)
print("")
print("")
print("Περιοχή III")
print("")
print("Cluster 18:")
neuron_movies_report(18)
print("")
print("Cluster 15:")
neuron_movies_report(15)
print("")
print("")
print("Περιοχή IV")
print("")
print("Cluster 16:")
neuron_movies_report(16)
print("")
print("Cluster 4:")
neuron_movies_report(4)
print("")
print("")
print("Περιοχή V")
print("")
print("Cluster 6:")
neuron_movies_report(6)
print("")
print("")
print("Περιοχή VI")
print("")
print("Cluster 13:")
neuron_movies_report(13)
print("")
print("")
print("Περιοχή VII")
print("")
print("Cluster 22:")
neuron_movies_report(22)

"""### Grid 30 x 30"""

n_columns = 30
n_rows = 30
som, bmus, ubmus, indices = train_som(n_columns, n_rows)

"""#### n_clusters = 30"""

clusters = clusters_report(30, som)

print("Περιοχή Ι (Drama)")
print("")
print("Cluster 20:")
neuron_movies_report(20)
print("")
print("Cluster 4:")
neuron_movies_report(4)
print("")
print("")
print("Περιοχή IΙ (Action - Adventure)")
print("")
print("Cluster 14:")
neuron_movies_report(14)
print("")
print("Cluster 28:")
neuron_movies_report(28)
print("")
print("Cluster 9:")
neuron_movies_report(9)
print("")
print("")
print("Περιοχή IΙI (Thriller - Crime)")
print("")
print("Cluster 2:")
neuron_movies_report(2)
print("")
print("Cluster 17:")
neuron_movies_report(17)
print("")
print("Cluster 6:")
neuron_movies_report(6)
print("")
print("Cluster 22:")
neuron_movies_report(22)
print("")
print("")
print("Περιοχή IV (Horror)")
print("")
print("Cluster 5:")
neuron_movies_report(5)
print("")
print("")
print("Περιοχή V (Comedy)")
print("")
print("Cluster 1:")
neuron_movies_report(1)
print("")
print("Cluster 11:")
neuron_movies_report(11)
print("")
print("")
print("Περιοχή VI (Romance)")
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("Cluster 13:")
neuron_movies_report(13)
print("")
print("")
print("Περιοχή VII (Animation - Short - Family)")
print("")
print("Cluster 23:")
neuron_movies_report(23)
print("")
print("Cluster 26:")
neuron_movies_report(26)
print("")
print("Cluster 18:")
neuron_movies_report(18)
print("")
print("")
print("Περιοχή VIII (Word Cinema)")
print("")
print("Cluster 3:")
neuron_movies_report(3)
print("")
print("Cluster 16:")
neuron_movies_report(16)
print("")
print("")
print("Περιοχή IX (Silent - Black and White)")
print("")
print("Cluster 29:")
neuron_movies_report(29)
print("")
print("")
print("Περιοχή X (Documentary)")
print("")
print("Cluster 19:")
neuron_movies_report(19)
print("")
print("")
print("Περιοχή XΙ (Indie)")
print("")
print("Cluster 12:")
neuron_movies_report(12)

"""#### n_clusters = 40"""

clusters = clusters_report(40, som)

print("Περιοχή Ι")
print("")
print("Cluster 35:")
neuron_movies_report(35)
print("")
print("")
print("Περιοχή ΙI")
print("")
print("Cluster 24:")
neuron_movies_report(24)
print("")
print("Cluster 11:")
neuron_movies_report(11)
print("")
print("")
print("Περιοχή III")
print("")
print("Cluster 14:")
neuron_movies_report(14)
print("")
print("")
print("Περιοχή IV")
print("")
print("Cluster 25:")
neuron_movies_report(25)
print("")
print("")
print("Περιοχή V")
print("")
print("Cluster 33:")
neuron_movies_report(33)
print("")
print("")
print("Περιοχή VI")
print("")
print("Cluster 20:")
neuron_movies_report(20)
print("")
print("Cluster 28:")
neuron_movies_report(28)
print("")
print("")
print("Περιοχή VII")
print("")
print("Cluster 27:")
neuron_movies_report(27)
print("")
print("")
print("Περιοχή VIII")
print("")
print("Cluster 6:")
neuron_movies_report(6)

"""## Σχόλια για Βελτιστοποίηση

Από την παραπάνω ανάλυση επιλέγουμε το **Grid 30x30** με **n_clusters=30**. Στην συγκεκριμένη περίπτωση αποτυπώθηκαν με επιτυχία τόσο οι συχνές κατηγορίες ταινιών ("Drama", "Comedy", "Thriller"), όσο και οι πιο σπάνιες ("Musical", "Black-and-white", "Documentary"), κάτι που δεν παρατηρήθηκε σε μικρότερους χάρτες. Δεν είχε νόημα να αναλύσουμε μεγαλύτερους χάρτες, καθώς όπως παρατηρήσαμε διασπάστηκαν κατηγορίες που ήταν σχετικές μεταξύ τους (πχ "Romance film" και "Romantic Drama"). Παρακάτω παρατίθεται για χάρην ευκολίας ξανά ο χάρτης (U-Matrix με clusters) και η ομαδοποίηση των κατηγοριών.

#### Βέλτιστος Χάρτης και Κατηγορίες
"""

clusters = clusters_report(30, som)

print("Περιοχή Ι (Drama)")
print("")
print("Cluster 20:")
neuron_movies_report(20)
print("")
print("Cluster 4:")
neuron_movies_report(4)
print("")
print("")
print("Περιοχή IΙ (Action - Adventure)")
print("")
print("Cluster 14:")
neuron_movies_report(14)
print("")
print("Cluster 28:")
neuron_movies_report(28)
print("")
print("Cluster 9:")
neuron_movies_report(9)
print("")
print("")
print("Περιοχή IΙI (Thriller - Crime)")
print("")
print("Cluster 2:")
neuron_movies_report(2)
print("")
print("Cluster 17:")
neuron_movies_report(17)
print("")
print("Cluster 6:")
neuron_movies_report(6)
print("")
print("Cluster 22:")
neuron_movies_report(22)
print("")
print("")
print("Περιοχή IV (Horror)")
print("")
print("Cluster 5:")
neuron_movies_report(5)
print("")
print("")
print("Περιοχή V (Comedy)")
print("")
print("Cluster 1:")
neuron_movies_report(1)
print("")
print("Cluster 11:")
neuron_movies_report(11)
print("")
print("")
print("Περιοχή VI (Romance)")
print("")
print("Cluster 8:")
neuron_movies_report(8)
print("")
print("Cluster 13:")
neuron_movies_report(13)
print("")
print("")
print("Περιοχή VII (Animation - Short - Family)")
print("")
print("Cluster 23:")
neuron_movies_report(23)
print("")
print("Cluster 26:")
neuron_movies_report(26)
print("")
print("Cluster 18:")
neuron_movies_report(18)
print("")
print("")
print("Περιοχή VIII (Word Cinema)")
print("")
print("Cluster 3:")
neuron_movies_report(3)
print("")
print("Cluster 16:")
neuron_movies_report(16)
print("")
print("")
print("Περιοχή IX (Silent - Black and White)")
print("")
print("Cluster 29:")
neuron_movies_report(29)
print("")
print("")
print("Περιοχή X (Documentary)")
print("")
print("Cluster 19:")
neuron_movies_report(19)
print("")
print("")
print("Περιοχή XΙ (Indie)")
print("")
print("Cluster 12:")
neuron_movies_report(12)

"""## Ανάλυση τοπολογικών ιδιοτήτων χάρτη SOM

Μετά το πέρας της εκπαίδευσης και του clustering έχουμε ένα χάρτη με τοπολογικές ιδιότητες ως προς τα είδη των ταίνιών της συλλογής μας, κάτι αντίστοιχο με την εικόνα στην αρχή της Εφαρμογής 2 αυτού του notebook (η συγκεκριμένη εικόνα είναι μόνο για εικονογράφιση, δεν έχει καμία σχέση με τη συλλογή δεδομένων και τις κατηγορίες μας).

Για τον τελικό χάρτη SOM που παράξαμε για τη συλλογή μας, αναλύουμε σε markdown με συγκεκριμένη αναφορά σε αριθμούς clusters και τη σημασιολογική ερμηνεία τους τις εξής τρεις τοπολογικές ιδιότητες του SOM: 

1. Δεδομένα που έχουν μεγαλύτερη πυκνότητα πιθανότητας στο χώρο εισόδου τείνουν να απεικονίζονται με περισσότερους νευρώνες στο χώρο μειωμένης διαστατικότητας. Παρακάτω φαίνονται κάποια παραδείγματα από συχνές και λιγότερο συχνές κατηγορίες ταινιών. 

2. Μακρινά πρότυπα εισόδου τείνουν να απεικονίζονται απομακρυσμένα στο χάρτη. Υπάρχουν χαρακτηριστικές κατηγορίες ταινιών που ήδη από μικρούς χάρτες τείνουν να τοποθετούνται σε διαφορετικά ή απομονωμένα σημεία του χάρτη.

3. Κοντινά πρότυπα εισόδου τείνουν να απεικονίζονται κοντά στο χάρτη. Σε μεγάλους χάρτες εντοπίσαμε είδη ταινιών και κοντινά τους υποείδη.



Εντοπίσαμε επίσης μεγάλα clusters και μικρά clusters που δεν έχουν σαφή χαρακτηριστικά καθώς και clusters συγκεκριμένων ειδών που μοιάζουν να μην έχουν τοπολογική συνάφεια με γύρω περιοχές. 



Τέλος, εντοπίσαμε clusters που έχουν κατά την άποψή μας ιδιαίτερο ενδιαφέρον στη συλλογή της ομάδας μας (data exploration / discovery value).

### Συχνές Κατηγορίες Ταινιών σε Νευρώνες

*   **Drama**: Η κατηγορία δράμα είναι η πιο συχνή κατηγορία τανιών που εμφανίζεται στους νευρώνες. Αρχικά, το μεγαλύτερο ποσοστό το παρατηρούμε προφανώς στην περιοχή Ι του χάρτη SOM, στα cluster 20 και 4, με 745 και 94 αντίστοιχα ταινίες το κάθε ένα. Επιπλέον, η κατηγορία αυτή παρατηρείται στην περιοχή ΙΙ (120 ταινίες) και στην περιοχή ΙΙΙ (363 ταινίες), συνδιαστικά με "Action/Adventure" και "Thriller" αντίστοιχα. Τέλος, εμφανίζεται και σε αρκετές ταινίες στις περιοχές V, VI του χάρτη, συνδιαστικά με Κωμωδία και Ρομαντική, ως "Comedy-Drama" και "Romantic-Drama" αντίστοιχα.

*   **Action - Adventure**: Η κατηγορία δράση-περιπέτεια είναι η δεύτερη πιο συχνή κατηγορία τανιών που εμφανίζεται στους νευρώνες. Το μεγαλύτερο ποσοστό παρατηρείται προφανώς στην περιοχή ΙΙ, στα cluster 28, 14 και 29, με 226, 188 και 103 τανίες αντίστοιχα. Επίσης, εμφανίζεται στην περιοχή I (cluster 20 και 4) συνδιαστικά με την κατηγορία "Drama". Τέλος, η κατηγορία αυτή παρατηρείται και στην περιοχή ΙΙI (211 ταινίες), συνδιαστικά με τη κατηγορία "Thriller". Προφανώς, εμφανίζεται και σε άλλα clusters τα οποία δεν μπορούμε να τα αναφέρουμε όλα, με χαμηλότερη όμως συχνότητα, όπως για παράδειγμα συνδιαστικά με τις κατηγορίες "Word Cinema" και "Horror".

*   **Comedy**: Η κατηγορία κωμωδία είναι μια πολύ συχνή κατηγορία τανιών που εμφανίζεται στους νευρώνες. Το μεγαλύτερο ποσοστό παρατηρείται προφανώς στην περιοχή V, στα cluster 1 και 11, με 469 και 188 τανίες αντίστοιχα. Επίσης, εμφανίζεται στην περιοχή VI (cluster 8 και 13) συνδιαστικά με την κατηγορία "Romantic". Τέλος, η κατηγορία comedy παρατηρείται και στις περιοχές VII (116 ταινίες) και X (23 ταινίες), συνδιαστικά με τις κατηγορίες "Animation" - "Short Film" και "Indie" αντίστοιχα.

*   **Thriller**: Η κατηγορία θρίλερ είναι κι αυτή μια αρκετά συχνή κατηγορία ταινιών που παρατηρούμε στους νευρώνες. Συγκεκριμένα, εμφανίζεται κατά το μεγαλύτερο ποσοστό στην περιοχή IΙΙ στα clusters 2, 17, 6 και 22, με 171, 127, 104 και 59 ταινίες αντίστοιχα. Επιπλέον, παρατηρείται στην περιοχή Ι συνδιαστικά με την κατηγορία "Drama" στα clusters 20 και 4. Αξίζει επίσης να σημειωθεί ότι η συγκεκριμένη κατηγορία "χωρίζεται" και σε επιμέρους μικρότερες, όπως "Crime Thriller" (169 ταινίες), "Crime Fiction" (335 ταινίες) και "Psychological Τhriller" (59 ταινίες), που εμφανίζονται στους νευρώνες της περιοχής ΙΙΙ.

### Σπάνιες Κατηγορίες Ταινιών σε Νευρώνες

Οι κατηγορίες ταινιών που εμφανίζονται λιγότερο στους νευρώνες και στα clusters, είναι στην ουσία πιο εξεζητημένες κατηγορίες που δεν έχουμε πολλά δείγματα ταινιών στο dataset μας. Συγκεκριμένα, μερικές από αυτές τις κατηγορίες είναι οι εξής: <br>
"Fairy tale", "Political satire", "Jungle Film", "Escape Film", "Propaganda film", "Airplanes and airports", "Christian film", "Feminist Film", κτλ.

### Μακρινά Πρότυπα Εισόδου

Μακρινά πρότυπα εισόδου τείνουν να απεικονίζονται απομακρυσμένα στο χάρτη. Υπάρχουν χαρακτηριστικές κατηγορίες ταινιών που τείνουν να τοποθετούνται σε διαφορετικά ή απομονωμένα σημεία του χάρτη. Τέτοιου είδους κατηγορίες είναι οι εξής:

*   **Drama**: Είναι η πιο μακρινή - απομονωμένη κατηγορία που παρατηρούμε. Βρίσκεται πάνω πάνω και δεξιά στο U-Matrix. Η συγκεκριμένη περιοχή του χάρτη έχει αποδοθεί στο cluster 20, που όπως είδαμε και προηγουμένως έχει 745 ταινίες κατηγορίας "Drama".

*   **Horror**: Είναι η περιοχή που βρίσκεται στο κέντρο και λίγο αριστερά στον U-Matrix. Έχει αποδωθεί στο cluster 5, που έχει συνολικά 224 ταινίες κατηγορίας "Horror".

*   **Comedy**: Είναι η περιοχή που βρίσκεται πάνω πάνω και αριστερά στον U-Matrix. Έχει αποδωθεί στο cluster 11 και 9, με συνολικά 657 ταινίες κατηγορίας "Comedy".

*   **Documentary - Biography**: Είναι η περιοχή που βρίσκεται στο κέντρο και λίγο κάτω δεξιά στον U-Matrix. Έχει αποδωθεί στο cluster 19, που έχει συνολικά 101 ταινίες κατηγορίας "Documentary" και "Biography".

### Κοντινά Πρότυπα Εισόδου

Κοντινά πρότυπα εισόδου τείνουν να απεικονίζονται κοντά στο χάρτη. Υπάρχουν χαρακτηριστικές κατηγορίες ταινιών που τείνουν να τοποθετούνται σε μικρές αποστάσεις η μία από την άλλη και να σχηματίζουν έτσι διαφορετικά υποείδη της κεντρικής κατηγορίας. Τέτοιου είδους κατηγορίες είναι οι εξής:

*   **Action με Adventure**: Είναι η περιοχή ΙΙ που βρίσκεται στο κέντρο και δεξιά στον U-Matrix. Έχει αποδωθεί στα cluster 14, 28 και 9. Οι βασικές κατηγορίες είναι η "Action" και η "Adventure" με χαρακτηριστικά υποείδη που προκύπτουν από αυτές να είναι η "Action/Adventure", "Western", "Spaghetti Western", "Fantasy Adventure", "Costume Adventure", "Superhero movie". Σε όλα τα παραδείγματα που εκτελέσαμε, πάντα αυτές οι δύο κατηγορίες είχαν τόσο κοντινά πρότυπα εισόδου η μία στην άλλη, που πολλές φορές θεωρούταν για χάρη ευκολίας ως μια κατηγορία.

*   **Thriller με Crime Fiction**: Είναι η περιοχή ΙΙΙ που βρίσκεται στο κέντρο και λίγο πάνω δεξιά στον U-Matrix. Έχει αποδωθεί στα cluster 2, 17, 6 και 22. Οι βασικές κατηγορίες είναι η "Thriller" και η "Crime Fiction", με υποείδη αντίστοιχα τα "Crime Thriller", "Psychological thriller", "Science Fiction" και "Mystery". Γενικά, σε όλες τις διαφορετικές περιπτώσεις μεγέθους χάρτη και αριθμό n_clusters που τρέξαμε, αυτές οι κατηγορίες πάντα τείνανε να σχηματίζονται κοντά η μία στην άλλη.

*   **Animation με Short Film και Family Film**: Είναι η περιοχή που βρίσκεται κάτω κάτω δεξία στον U-Matrix. Έχει αποδωθεί στα cluster 23, 26 και 18. Χαρακτηριστικά υποείδη που προκύπτουν από αυτές είναι η "Children\'s", "Children\'s/Family", "Children\'s Fantasy", "Computer Animation" και "Animated cartoon". Γενικά, σε όλες τις διαφορετικές περιπτώσεις μεγέθους χάρτη και αριθμό n_clusters που τρέξαμε, αυτές οι κατηγορίες πάντα τείνανε να σχηματίζονται κοντά η μία στην άλλη.

### Cluster με Ασαφή Χαρακτηριστικά

Εξετάσαμε **όλα** τα clusters που προέκυψαν από τον k-Means και καταλήξαμε ότι αυτά με τα πιο ασαφή χαρακτηριστικά είναι τα παρακάτω.<br><br>
<i><u>Σημείωση</u>: Γενικά δεν παρατηρήσαμε μεγάλες ασάφειες όσο αναφορά τα χαρακτηριστικά, ούτε στα μεγάλα ούτε στα μικρά clusters, γεγονός που επιβεβαιώνει ότι πετύχαμε μια σχετικά καλή ομαδοποίηση.</i>

#### Μεγάλα Cluster
"""

print("Cluster 0:")
neuron_movies_report(0)

print("Cluster 25:")
neuron_movies_report(25)

print("Cluster 21:")
neuron_movies_report(21)

"""*   **Cluster 0**: Στο συγκεκριμένο cluster παρατηρήσαμε ότι συνυπάρχουν με σχετικά υψηλό ποσοστό δύο κατηγορίες οι οποίες δεν έχουν και τόσο κοινά χαρακτηριστικά. Αυτές είναι η "Comedy film" και η "Crime Fiction".

*   **Cluster 25**: Στο συγκεκριμένο cluster παρατηρήσαμε ότι οι δύο πρώτες κατηγορίες ("Drama", "Comedy") έχουν το ίδιο πλήθος ταινιών με μεγάλη συχνότητα. Οι τανίες αυτές θα μπορούσαν να ταξινομηθούν καλύτερα είτε στην περιοχή Ι (Drama) είτε στην περιοχή V (Comedy). Επίσης, στην περίπτωση που το περιεχόμενο της ταινίας ήταν και δραματική και κωμωδία θα άνηκε στην κατηγρία "Comedy-drama".

*   **Cluster 21**: Στο συγκεκριμένο cluster παρατηρήσαμε ότι συνυπάρχουν με σχετικά υψηλό ποσοστό δύο κατηγορίες οι οποίες δεν έχουν και τόσο κοινό περιεχόμενο. Αυτές είναι η "Action/Adventure" και η "Comedy".

#### Μικρά Cluster
"""

print("Cluster 27:")
neuron_movies_report(27)

"""Έχοντας εξετάσει όλα τα clusters (και τα 30), το μοναδικό μικρό με ασαφή χαρακτηριστικά ήταν το cluster 27. Συγκεκριμένα, παρατηρήσαμε ότι η πρώτη κατηγορία ("Japanese Movies") δεν μας δίνει σαφή πληροφορία για το περιεχόμενο των ταινιών παρά μόνο για την προέλευση. Πρόκειται δηλαδή για μια "υπερκατηγορία" που μπορεί να περιλαμβάνει και επιμέρους, επομένως δεν μας είναι ιδιαίτερα χρήσιμο στην κατηγοριοποίηση.

### Cluster χωρίς τοπολογική συνάφεια με γύρω περιοχές

Παρτηρώντας τον U-Matrix και τον πίνακα των clusters έγινε αντιλυπτό ότι στην κάτω δεξία γωνία συνορεύουν με μικρές αποστάσεις (ανοιχτό χρωμά) τρία clusters τα οποία δεν έχουν τοπολογική συνάφεια μεταξύ τους. Αυτά είναι τα 19, 0, 29 και 9. Συγκεκριμένα, οι κατηγορίες με την μεγαλύτερη συχνότητα εμφάνισης ("Documentary", "Comedy", "Silent film" και "Action/Adventure"), δεν είναι απολύτως σχετικές μεταξύ τους.
"""

print("Cluster 19")
neuron_movies_report(19)
print("")
print("Cluster 0")
neuron_movies_report(0)
print("")
print("Cluster 29")
neuron_movies_report(29)
print("")
print("Cluster 9")
neuron_movies_report(9)

"""**Πιθανές Ερμηνείες**<br>
Προφανώς η τοποθέτηση όλων των κατηγοριών σε **2 διαστάσεις** δεν μπορεί να οδηγήσει σε μια απόλυτη τοπολογία. Αυτό συμβαίνει διότι, αφενός δεν υπάρχει κάποια απόλυτη εξ ορισμού τοπολογία για τα κινηματογραφικά είδη ακόμα και σε πολλές διαστάσεις, αφετέρου γιατί πραγματοποιούμε **μείωση διαστατικότητας**. Επιπλέον, αν είχαμε ίσο αριθμό ταινιών ανά κατηγορία (**balanced dataset**), λογικά θα είχαμε πετύχει μια καλύτερη ομαδοποίηση. Παρατηρήσαμε επίσης ότι υπήρχαν κατηγορίες με σχεδόν τα **ίδια ονόματα** όπως "Action"-"Adventure"-"Action/Adventure", "Comedy"-"Comedy film" και "Biographical film"-"Biography". Τέλος, αρκετές ταινίες με **ασαφή περιεχόμενο** με αποτέλεσμα να μην μπορούν να κατηγοριοποιηθούν σωστά ούτε από τον άνθρωπο.

### Ενδιαφέροντα Clusters

Παρακάτω συγκεντρώσαμε κάποια clusters τα οποία, παρόλο που αποτελούνται από μικρό αριθμό νευρώνων, μας έκαναν ιδιαίτερη εντύπωση καθώς αποτύπωσαν σπάνιες κατηγορίες με μεγάλη επιτυχία.
"""

print("Cluster 29 (Silent - Black and White)")
neuron_movies_report(29)

print("Cluster 19 (Documentary - Biography)")
neuron_movies_report(19)

print("Cluster 12 (Indie)")
neuron_movies_report(12)

print("Cluster 15 (Musical)")
neuron_movies_report(15)

"""**Σχόλιο**: Οι κατηγορίες αυτές έγιναν αντιληπτές, καθώς μελετούσαμε μεγαλύτερα Grid. Αυτό ήταν αναμενόμενο από την στιγμή που όσο μεγαλώνει το πλέγμα, τόσους περισσότερους νευρώνες έχουμε και άρα τόσο καλύτερη απεικόνιση κατηγοριών στον χάρτη επιτυγχάνουμε. Βέβαια, υπάρχει ο κίνδυνος αν αυξηθεί υπερβολικά το grid παράλληλα με τον αριθμό των clusters, να διασπαστούν κατηγορίες που είναι σχετικές μεταξύ τους."""